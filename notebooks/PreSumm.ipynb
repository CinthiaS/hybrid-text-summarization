{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"PreSumm.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOxsVD6k5bbCH76Th13s8Qh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"WArU9HmWG_CV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612829749322,"user_tz":180,"elapsed":28470,"user":{"displayName":"Cinthia Mikaela de Souza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSYWVyWfXKPRe-m_hW9EaymViE56Sd6-54Bvh6=s64","userId":"06359001126903823254"}},"outputId":"8aed6a73-21f5-4682-d66a-01390a4f6044"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"H7mkxVqtHGNN"},"source":["import os\n","os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z875m0MaHIri","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5b618625-956c-4fd3-b814-fc6ee597f733"},"source":["!pip install torch==1.1.0\n","!pip install pytorch-pretrained-bert\n","!pip install tensorboardX\n","!pip install pyrouge"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting torch==1.1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fsGqGA7VAGcj","executionInfo":{"status":"ok","timestamp":1612829900488,"user_tz":180,"elapsed":150408,"user":{"displayName":"Cinthia Mikaela de Souza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSYWVyWfXKPRe-m_hW9EaymViE56Sd6-54Bvh6=s64","userId":"06359001126903823254"}},"outputId":"d734858c-2438-4c9a-b66f-38fd415e97f7"},"source":["!pip install pytorch_transformers"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting pytorch_transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/b7/d3d18008a67e0b968d1ab93ad444fc05699403fa662f634b2f2c318a508b/pytorch_transformers-1.2.0-py3-none-any.whl (176kB)\n","\r\u001b[K     |█▉                              | 10kB 22.8MB/s eta 0:00:01\r\u001b[K     |███▊                            | 20kB 29.4MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 30kB 21.9MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 40kB 25.2MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 51kB 23.6MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 61kB 25.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 71kB 18.9MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 81kB 20.1MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 92kB 19.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 102kB 20.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 112kB 20.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 122kB 20.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 133kB 20.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 143kB 20.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 153kB 20.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 163kB 20.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 174kB 20.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 184kB 20.4MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (1.19.5)\n","Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (1.1.0)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 49.3MB/s \n","\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (2.23.0)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (1.17.4)\n","Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/67/e42bd1181472c95c8cda79305df848264f2a7f62740995a46945d9797b67/sentencepiece-0.1.95-cp36-cp36m-manylinux2014_x86_64.whl (1.2MB)\n","\u001b[K     |████████████████████████████████| 1.2MB 41.8MB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (4.41.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch_transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch_transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch_transformers) (1.0.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_transformers) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_transformers) (1.24.3)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_transformers) (0.10.0)\n","Requirement already satisfied: botocore<1.21.0,>=1.20.4 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_transformers) (1.20.4)\n","Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_transformers) (0.3.4)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.21.0,>=1.20.4->boto3->pytorch_transformers) (2.8.1)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=5456117c9031def3076e117e37534fe0d5239711ab481038c9083327bc4fc60a\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: sacremoses, sentencepiece, pytorch-transformers\n","Successfully installed pytorch-transformers-1.2.0 sacremoses-0.0.43 sentencepiece-0.1.95\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k2JlKT-M_RGu","executionInfo":{"status":"ok","timestamp":1612830327776,"user_tz":180,"elapsed":776,"user":{"displayName":"Cinthia Mikaela de Souza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSYWVyWfXKPRe-m_hW9EaymViE56Sd6-54Bvh6=s64","userId":"06359001126903823254"}},"outputId":"e6b23985-99dd-4950-9a75-9b77fb69b8ec"},"source":["cd /content/drive/My Drive/Colab Notebooks/Mestrado/Extractive Summarization/PreSumm/src"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/Mestrado/Extractive Summarization/PreSumm/src\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z8GUe8Qf_x7C","executionInfo":{"status":"ok","timestamp":1612831401273,"user_tz":180,"elapsed":11847,"user":{"displayName":"Cinthia Mikaela de Souza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSYWVyWfXKPRe-m_hW9EaymViE56Sd6-54Bvh6=s64","userId":"06359001126903823254"}},"outputId":"67921293-b973-49a9-9338-142940abee95"},"source":["!python train.py  -task abs -mode train -bert_data_path ../../BertSum/bert_data/text -dec_dropout 0.2  -model_path ../models -sep_optim true -lr_bert 0.002 -lr_dec 0.2 -save_checkpoint_steps 5 -batch_size 140 -train_steps 10 -report_every 50 -accum_count 5 -use_bert_emb true -use_interval true -warmup_steps_bert 20000 -warmup_steps_dec 10000 -max_pos 512 -visible_gpus 0 -log_file ../logs/abs_bert_cnndm "],"execution_count":null,"outputs":[{"output_type":"stream","text":["[2021-02-09 00:43:10,706 INFO] Namespace(accum_count=5, alpha=0.6, batch_size=140, beam_size=5, bert_data_path='../../BertSum/bert_data/text', beta1=0.9, beta2=0.999, block_trigram=True, dec_dropout=0.2, dec_ff_size=2048, dec_heads=8, dec_hidden_size=768, dec_layers=6, enc_dropout=0.2, enc_ff_size=512, enc_hidden_size=512, enc_layers=6, encoder='bert', ext_dropout=0.2, ext_ff_size=2048, ext_heads=8, ext_hidden_size=768, ext_layers=2, finetune_bert=True, generator_shard_size=32, gpu_ranks=[0], label_smoothing=0.1, large=False, load_from_extractive='', log_file='../logs/abs_bert_cnndm', lr=1, lr_bert=0.002, lr_dec=0.2, max_grad_norm=0, max_length=150, max_pos=512, max_tgt_len=140, min_length=15, mode='train', model_path='../models', optim='adam', param_init=0, param_init_glorot=True, recall_eval=False, report_every=50, report_rouge=True, result_path='../results/cnndm', save_checkpoint_steps=5, seed=666, sep_optim=True, share_emb=False, task='abs', temp_dir='../temp', test_all=False, test_batch_size=200, test_from='', test_start_from=-1, train_from='', train_steps=10, use_bert_emb=True, use_interval=True, visible_gpus='0', warmup_steps=8000, warmup_steps_bert=20000, warmup_steps_dec=10000, world_size=1)\n","[2021-02-09 00:43:10,707 INFO] Device ID 0\n","[2021-02-09 00:43:10,707 INFO] Device cuda\n","[2021-02-09 00:43:10,792 INFO] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at ../temp/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","[2021-02-09 00:43:10,793 INFO] Model config {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"pad_token_id\": 0,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","[2021-02-09 00:43:10,838 INFO] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at ../temp/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","[2021-02-09 00:43:20,174 INFO] AbsSummarizer(\n","  (bert): Bert(\n","    (model): BertModel(\n","      (embeddings): BertEmbeddings(\n","        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","        (position_embeddings): Embedding(512, 768)\n","        (token_type_embeddings): Embedding(2, 768)\n","        (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1)\n","      )\n","      (encoder): BertEncoder(\n","        (layer): ModuleList(\n","          (0): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","          (1): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","          (2): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","          (3): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","          (4): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","          (5): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","          (6): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","          (7): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","          (8): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","          (9): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","          (10): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","          (11): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","        )\n","      )\n","      (pooler): BertPooler(\n","        (dense): Linear(in_features=768, out_features=768, bias=True)\n","        (activation): Tanh()\n","      )\n","    )\n","  )\n","  (decoder): TransformerDecoder(\n","    (embeddings): Embedding(30522, 768, padding_idx=0)\n","    (pos_emb): PositionalEncoding(\n","      (dropout): Dropout(p=0.2)\n","    )\n","    (transformer_layers): ModuleList(\n","      (0): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n","          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n","          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n","          (softmax): Softmax()\n","          (dropout): Dropout(p=0.2)\n","          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n","          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n","          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n","          (softmax): Softmax()\n","          (dropout): Dropout(p=0.2)\n","          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n","          (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.2)\n","          (dropout_2): Dropout(p=0.2)\n","        )\n","        (layer_norm_1): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.2)\n","      )\n","      (1): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n","          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n","          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n","          (softmax): Softmax()\n","          (dropout): Dropout(p=0.2)\n","          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n","          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n","          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n","          (softmax): Softmax()\n","          (dropout): Dropout(p=0.2)\n","          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n","          (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.2)\n","          (dropout_2): Dropout(p=0.2)\n","        )\n","        (layer_norm_1): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.2)\n","      )\n","      (2): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n","          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n","          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n","          (softmax): Softmax()\n","          (dropout): Dropout(p=0.2)\n","          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n","          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n","          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n","          (softmax): Softmax()\n","          (dropout): Dropout(p=0.2)\n","          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n","          (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.2)\n","          (dropout_2): Dropout(p=0.2)\n","        )\n","        (layer_norm_1): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.2)\n","      )\n","      (3): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n","          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n","          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n","          (softmax): Softmax()\n","          (dropout): Dropout(p=0.2)\n","          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n","          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n","          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n","          (softmax): Softmax()\n","          (dropout): Dropout(p=0.2)\n","          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n","          (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.2)\n","          (dropout_2): Dropout(p=0.2)\n","        )\n","        (layer_norm_1): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.2)\n","      )\n","      (4): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n","          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n","          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n","          (softmax): Softmax()\n","          (dropout): Dropout(p=0.2)\n","          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n","          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n","          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n","          (softmax): Softmax()\n","          (dropout): Dropout(p=0.2)\n","          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n","          (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.2)\n","          (dropout_2): Dropout(p=0.2)\n","        )\n","        (layer_norm_1): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.2)\n","      )\n","      (5): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n","          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n","          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n","          (softmax): Softmax()\n","          (dropout): Dropout(p=0.2)\n","          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n","          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n","          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n","          (softmax): Softmax()\n","          (dropout): Dropout(p=0.2)\n","          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n","          (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.2)\n","          (dropout_2): Dropout(p=0.2)\n","        )\n","        (layer_norm_1): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.2)\n","      )\n","    )\n","    (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n","  )\n","  (generator): Sequential(\n","    (0): Linear(in_features=768, out_features=30522, bias=True)\n","    (1): LogSoftmax()\n","  )\n",")\n","[2021-02-09 00:43:20,297 INFO] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at ../temp/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","gpu_rank 0\n","[2021-02-09 00:43:20,328 INFO] * number of parameters: 180222522\n","[2021-02-09 00:43:20,328 INFO] Start training...\n","[2021-02-09 00:43:20,331 INFO] Loading train dataset from ../../BertSum/bert_data/text.train.8.bert.pt, number of examples: 1\n","Traceback (most recent call last):\n","  File \"train.py\", line 122, in <module>\n","    train_abs(args, device_id)\n","  File \"/content/drive/My Drive/Colab Notebooks/Mestrado/Extractive Summarization/PreSumm/src/train_abstractive.py\", line 273, in train_abs\n","    train_abs_single(args, device_id)\n","  File \"/content/drive/My Drive/Colab Notebooks/Mestrado/Extractive Summarization/PreSumm/src/train_abstractive.py\", line 334, in train_abs_single\n","    trainer.train(train_iter_fct, args.train_steps)\n","  File \"/content/drive/My Drive/Colab Notebooks/Mestrado/Extractive Summarization/PreSumm/src/models/trainer.py\", line 142, in train\n","    for i, batch in enumerate(train_iter):\n","  File \"/content/drive/My Drive/Colab Notebooks/Mestrado/Extractive Summarization/PreSumm/src/models/data_loader.py\", line 142, in __iter__\n","    for batch in self.cur_iter:\n","  File \"/content/drive/My Drive/Colab Notebooks/Mestrado/Extractive Summarization/PreSumm/src/models/data_loader.py\", line 278, in __iter__\n","    for idx, minibatch in enumerate(self.batches):\n","  File \"/content/drive/My Drive/Colab Notebooks/Mestrado/Extractive Summarization/PreSumm/src/models/data_loader.py\", line 256, in create_batches\n","    for buffer in self.batch_buffer(data, self.batch_size * 300):\n","  File \"/content/drive/My Drive/Colab Notebooks/Mestrado/Extractive Summarization/PreSumm/src/models/data_loader.py\", line 224, in batch_buffer\n","    ex = self.preprocess(ex, self.is_test)\n","  File \"/content/drive/My Drive/Colab Notebooks/Mestrado/Extractive Summarization/PreSumm/src/models/data_loader.py\", line 195, in preprocess\n","    tgt = ex['tgt'][:self.args.max_tgt_len][:-1]+[2]\n","KeyError: 'tgt'\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":153},"id":"TZFjJdVf_MwA","executionInfo":{"status":"error","timestamp":1612744601307,"user_tz":180,"elapsed":203235,"user":{"displayName":"Cinthia Mikaela de Souza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSYWVyWfXKPRe-m_hW9EaymViE56Sd6-54Bvh6=s64","userId":"06359001126903823254"}},"outputId":"f478a6bb-d619-470a-c0e9-6d9c7b978644"},"source":[" python train.py -task abs -mode test -batch_size 3000 -test_batch_size 500 -bert_data_path ../../BertSum/bert_data -log_file ../logs/val_abs_bert_cnndm -model_path MODEL_PATH -sep_optim true -use_interval true -visible_gpus 1 -max_pos 512 -max_length 200 -alpha 0.95 -min_length 50 -result_path ../logs/abs_bert_cnndm "],"execution_count":null,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-6d949590331f>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    python train.py -task abs -mode test -batch_size 3000 -test_batch_size 500 -bert_data_path ../../BertSum/bert_data -log_file ../logs/val_abs_bert_cnndm -model_path MODEL_PATH -sep_optim true -use_interval true -visible_gpus 1 -max_pos 512 -max_length 200 -alpha 0.95 -min_length 50 -result_path ../logs/abs_bert_cnndm\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5H_FHayEL5br","executionInfo":{"status":"ok","timestamp":1612832274859,"user_tz":180,"elapsed":13064,"user":{"displayName":"Cinthia Mikaela de Souza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSYWVyWfXKPRe-m_hW9EaymViE56Sd6-54Bvh6=s64","userId":"06359001126903823254"}},"outputId":"c3ae0d51-cf84-4b3e-8a4c-73d4339703af"},"source":[" !python train.py -task ext -mode test -batch_size 3000 -test_batch_size 500 -bert_data_path ../../BertSum/bert_data/text -log_file ../logs/val_abs_bert_cnndm -model_path ../models -test_from ../models/bertext_cnndm_transformer.pt  -sep_optim true -use_interval true -visible_gpus 0 -max_pos 512 -max_length 200 -alpha 0.95 -min_length 50 -result_path ../logs/abs_bert_cnndm "],"execution_count":null,"outputs":[{"output_type":"stream","text":["[2021-02-09 00:57:42,951 INFO] Loading checkpoint from ../models/bertext_cnndm_transformer.pt\n","Namespace(accum_count=1, alpha=0.95, batch_size=3000, beam_size=5, bert_data_path='../../BertSum/bert_data/text', beta1=0.9, beta2=0.999, block_trigram=True, dec_dropout=0.2, dec_ff_size=2048, dec_heads=8, dec_hidden_size=768, dec_layers=6, enc_dropout=0.2, enc_ff_size=512, enc_hidden_size=512, enc_layers=6, encoder='bert', ext_dropout=0.2, ext_ff_size=2048, ext_heads=8, ext_hidden_size=768, ext_layers=2, finetune_bert=True, generator_shard_size=32, gpu_ranks=[0], label_smoothing=0.1, large=False, load_from_extractive='', log_file='../logs/val_abs_bert_cnndm', lr=1, lr_bert=0.002, lr_dec=0.002, max_grad_norm=0, max_length=200, max_pos=512, max_tgt_len=140, min_length=50, mode='test', model_path='../models', optim='adam', param_init=0, param_init_glorot=True, recall_eval=False, report_every=1, report_rouge=True, result_path='../logs/abs_bert_cnndm', save_checkpoint_steps=5, seed=666, sep_optim=True, share_emb=False, task='ext', temp_dir='../temp', test_all=False, test_batch_size=500, test_from='../models/bertext_cnndm_transformer.pt', test_start_from=-1, train_from='', train_steps=1000, use_bert_emb=False, use_interval=True, visible_gpus='0', warmup_steps=8000, warmup_steps_bert=8000, warmup_steps_dec=8000, world_size=1)\n","[2021-02-09 00:57:45,424 INFO] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at ../temp/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","[2021-02-09 00:57:45,426 INFO] Model config {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"pad_token_id\": 0,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","[2021-02-09 00:57:45,453 INFO] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at ../temp/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","[2021-02-09 00:57:53,226 INFO] Loading test dataset from ../../BertSum/bert_data/text.test.0.bert.pt, number of examples: 1\n","gpu_rank 0\n","[2021-02-09 00:57:53,242 INFO] * number of parameters: 120512513\n","Traceback (most recent call last):\n","  File \"train.py\", line 155, in <module>\n","    test_ext(args, device_id, cp, step)\n","  File \"/content/drive/My Drive/Colab Notebooks/Mestrado/Extractive Summarization/PreSumm/src/train_extractive.py\", line 197, in test_ext\n","    trainer.test(test_iter, step)\n","  File \"/content/drive/My Drive/Colab Notebooks/Mestrado/Extractive Summarization/PreSumm/src/models/trainer_ext.py\", line 233, in test\n","    for batch in test_iter:\n","  File \"/content/drive/My Drive/Colab Notebooks/Mestrado/Extractive Summarization/PreSumm/src/models/data_loader.py\", line 142, in __iter__\n","    for batch in self.cur_iter:\n","  File \"/content/drive/My Drive/Colab Notebooks/Mestrado/Extractive Summarization/PreSumm/src/models/data_loader.py\", line 278, in __iter__\n","    for idx, minibatch in enumerate(self.batches):\n","  File \"/content/drive/My Drive/Colab Notebooks/Mestrado/Extractive Summarization/PreSumm/src/models/data_loader.py\", line 256, in create_batches\n","    for buffer in self.batch_buffer(data, self.batch_size * 300):\n","  File \"/content/drive/My Drive/Colab Notebooks/Mestrado/Extractive Summarization/PreSumm/src/models/data_loader.py\", line 224, in batch_buffer\n","    ex = self.preprocess(ex, self.is_test)\n","  File \"/content/drive/My Drive/Colab Notebooks/Mestrado/Extractive Summarization/PreSumm/src/models/data_loader.py\", line 195, in preprocess\n","    tgt = ex['tgt'][:self.args.max_tgt_len][:-1]+[2]\n","KeyError: 'tgt'\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IxGDRjj_QsM9","executionInfo":{"status":"ok","timestamp":1612832046200,"user_tz":180,"elapsed":1991,"user":{"displayName":"Cinthia Mikaela de Souza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSYWVyWfXKPRe-m_hW9EaymViE56Sd6-54Bvh6=s64","userId":"06359001126903823254"}},"outputId":"2d3e8e4e-ace2-4e62-9584-9b16ce472332"},"source":["!python train.py -mode test -text_src ../../BertSum/raw_/text/plosone_PMC3016643.story -test_from bertext_cnndm_transformer.pt"],"execution_count":null,"outputs":[{"output_type":"stream","text":["usage: train.py [-h] [-task {ext,abs}] [-encoder {bert,baseline}]\n","                [-mode {train,validate,test}] [-bert_data_path BERT_DATA_PATH]\n","                [-model_path MODEL_PATH] [-result_path RESULT_PATH]\n","                [-temp_dir TEMP_DIR] [-batch_size BATCH_SIZE]\n","                [-test_batch_size TEST_BATCH_SIZE] [-max_pos MAX_POS]\n","                [-use_interval [USE_INTERVAL]] [-large [LARGE]]\n","                [-load_from_extractive LOAD_FROM_EXTRACTIVE]\n","                [-sep_optim [SEP_OPTIM]] [-lr_bert LR_BERT] [-lr_dec LR_DEC]\n","                [-use_bert_emb [USE_BERT_EMB]] [-share_emb [SHARE_EMB]]\n","                [-finetune_bert [FINETUNE_BERT]] [-dec_dropout DEC_DROPOUT]\n","                [-dec_layers DEC_LAYERS] [-dec_hidden_size DEC_HIDDEN_SIZE]\n","                [-dec_heads DEC_HEADS] [-dec_ff_size DEC_FF_SIZE]\n","                [-enc_hidden_size ENC_HIDDEN_SIZE] [-enc_ff_size ENC_FF_SIZE]\n","                [-enc_dropout ENC_DROPOUT] [-enc_layers ENC_LAYERS]\n","                [-ext_dropout EXT_DROPOUT] [-ext_layers EXT_LAYERS]\n","                [-ext_hidden_size EXT_HIDDEN_SIZE] [-ext_heads EXT_HEADS]\n","                [-ext_ff_size EXT_FF_SIZE] [-label_smoothing LABEL_SMOOTHING]\n","                [-generator_shard_size GENERATOR_SHARD_SIZE] [-alpha ALPHA]\n","                [-beam_size BEAM_SIZE] [-min_length MIN_LENGTH]\n","                [-max_length MAX_LENGTH] [-max_tgt_len MAX_TGT_LEN]\n","                [-param_init PARAM_INIT]\n","                [-param_init_glorot [PARAM_INIT_GLOROT]] [-optim OPTIM]\n","                [-lr LR] [-beta1 BETA1] [-beta2 BETA2]\n","                [-warmup_steps WARMUP_STEPS]\n","                [-warmup_steps_bert WARMUP_STEPS_BERT]\n","                [-warmup_steps_dec WARMUP_STEPS_DEC]\n","                [-max_grad_norm MAX_GRAD_NORM]\n","                [-save_checkpoint_steps SAVE_CHECKPOINT_STEPS]\n","                [-accum_count ACCUM_COUNT] [-report_every REPORT_EVERY]\n","                [-train_steps TRAIN_STEPS] [-recall_eval [RECALL_EVAL]]\n","                [-visible_gpus VISIBLE_GPUS] [-gpu_ranks GPU_RANKS]\n","                [-log_file LOG_FILE] [-seed SEED] [-test_all [TEST_ALL]]\n","                [-test_from TEST_FROM] [-test_start_from TEST_START_FROM]\n","                [-train_from TRAIN_FROM] [-report_rouge [REPORT_ROUGE]]\n","                [-block_trigram [BLOCK_TRIGRAM]]\n","train.py: error: unrecognized arguments: -text_src ../../BertSum/raw_stories/text/plosone_PMC3016643.story\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LoTKDMYzZOgJ","executionInfo":{"status":"ok","timestamp":1612835817891,"user_tz":180,"elapsed":3136,"user":{"displayName":"Cinthia Mikaela de Souza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSYWVyWfXKPRe-m_hW9EaymViE56Sd6-54Bvh6=s64","userId":"06359001126903823254"}},"outputId":"ec4ef635-15b2-484a-c62c-6a8f66518299"},"source":["!pyrouge_set_rouge_path '/content/drive/My Drive/Colab Notebooks/Mestrado/Extractive Summarization/BertSum/src/pyrouge/tools/ROUGE-1.5.5'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2021-02-09 01:56:55,100 [MainThread  ] [INFO ]  Set ROUGE home directory to /content/drive/My Drive/Colab Notebooks/Mestrado/Extractive Summarization/BertSum/src/pyrouge/tools/ROUGE-1.5.5.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"myjAmln0Uo-6","executionInfo":{"status":"ok","timestamp":1612836732004,"user_tz":180,"elapsed":1035,"user":{"displayName":"Cinthia Mikaela de Souza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSYWVyWfXKPRe-m_hW9EaymViE56Sd6-54Bvh6=s64","userId":"06359001126903823254"}},"outputId":"dd87372b-88bd-4b4a-fd68-5f24813fb962"},"source":["!python train.py -mode test -encoder bert -task ext -test_from ../models/bertext_cnndm_transformer.pt -bert_data_path ../bert_data/text"],"execution_count":null,"outputs":[{"output_type":"stream","text":["python3: can't open file 'train.py': [Errno 2] No such file or directory\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NYct3K_KXWyk","executionInfo":{"status":"ok","timestamp":1612833533242,"user_tz":180,"elapsed":1051,"user":{"displayName":"Cinthia Mikaela de Souza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSYWVyWfXKPRe-m_hW9EaymViE56Sd6-54Bvh6=s64","userId":"06359001126903823254"}},"outputId":"5bfd9330-02cc-4e17-9cec-62ae6aa99afa"},"source":["cd ../src"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/Mestrado/Extractive Summarization/PreSumm/src\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZIFdiDbKXjaF","executionInfo":{"status":"ok","timestamp":1612833506909,"user_tz":180,"elapsed":760,"user":{"displayName":"Cinthia Mikaela de Souza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSYWVyWfXKPRe-m_hW9EaymViE56Sd6-54Bvh6=s64","userId":"06359001126903823254"}},"outputId":"7fd0aa9c-45f7-4013-eceb-3f5e6fd5de35"},"source":["cd ../raw_data"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/Mestrado/Extractive Summarization/PreSumm/raw_data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"J5rQLo9PXYjY"},"source":["import gc\n","import glob\n","import hashlib\n","import itertools\n","import json\n","import os\n","import random\n","import re\n","import subprocess\n","from collections import Counter\n","from os.path import join as pjoin\n","\n","import torch\n","from multiprocess import Pool\n","\n","from others.logging import logger\n","from others.tokenization import BertTokenizer\n","from pytorch_transformers import XLNetTokenizer\n","\n","from others.utils import clean\n","from prepro.utils import _get_word_ngrams\n","\n","import xml.etree.ElementTree as ET\n","\n","nyt_remove_words = [\"photo\", \"graph\", \"chart\", \"map\", \"table\", \"drawing\"]\n","\n","\n","def recover_from_corenlp(s):\n","    s = re.sub(r' \\'{\\w}', '\\'\\g<1>', s)\n","    s = re.sub(r'\\'\\' {\\w}', '\\'\\'\\g<1>', s)\n","\n","\n","\n","def load_json(p, lower):\n","    source = []\n","    tgt = []\n","    flag = False\n","    for sent in json.load(open(p))['sentences']:\n","        tokens = [t['word'] for t in sent['tokens']]\n","        if (lower):\n","            tokens = [t.lower() for t in tokens]\n","        if (tokens[0] == '@highlight'):\n","            flag = True\n","            tgt.append([])\n","            continue\n","        if (flag):\n","            tgt[-1].extend(tokens)\n","        else:\n","            source.append(tokens)\n","\n","    source = [clean(' '.join(sent)).split() for sent in source]\n","    tgt = [clean(' '.join(sent)).split() for sent in tgt]\n","    return source, tgt\n","\n","\n","\n","def load_xml(p):\n","    tree = ET.parse(p)\n","    root = tree.getroot()\n","    title, byline, abs, paras = [], [], [], []\n","    title_node = list(root.iter('hedline'))\n","    if (len(title_node) > 0):\n","        try:\n","            title = [p.text.lower().split() for p in list(title_node[0].iter('hl1'))][0]\n","        except:\n","            print(p)\n","\n","    else:\n","        return None, None\n","    byline_node = list(root.iter('byline'))\n","    byline_node = [n for n in byline_node if n.attrib['class'] == 'normalized_byline']\n","    if (len(byline_node) > 0):\n","        byline = byline_node[0].text.lower().split()\n","    abs_node = list(root.iter('abstract'))\n","    if (len(abs_node) > 0):\n","        try:\n","            abs = [p.text.lower().split() for p in list(abs_node[0].iter('p'))][0]\n","        except:\n","            print(p)\n","\n","    else:\n","        return None, None\n","    abs = ' '.join(abs).split(';')\n","    abs[-1] = abs[-1].replace('(m)', '')\n","    abs[-1] = abs[-1].replace('(s)', '')\n","\n","    for ww in nyt_remove_words:\n","        abs[-1] = abs[-1].replace('(' + ww + ')', '')\n","    abs = [p.split() for p in abs]\n","    abs = [p for p in abs if len(p) > 2]\n","\n","    for doc_node in root.iter('block'):\n","        att = doc_node.get('class')\n","        # if(att == 'abstract'):\n","        #     abs = [p.text for p in list(f.iter('p'))]\n","        if (att == 'full_text'):\n","            paras = [p.text.lower().split() for p in list(doc_node.iter('p'))]\n","            break\n","    if (len(paras) > 0):\n","        if (len(byline) > 0):\n","            paras = [title + ['[unused3]'] + byline + ['[unused4]']] + paras\n","        else:\n","            paras = [title + ['[unused3]']] + paras\n","\n","        return paras, abs\n","    else:\n","        return None, None\n","\n","\n","def tokenize(args):\n","    stories_dir = os.path.abspath(args.raw_path)\n","    tokenized_stories_dir = os.path.abspath(args.save_path)\n","\n","    print(\"Preparing to tokenize %s to %s...\" % (stories_dir, tokenized_stories_dir))\n","    stories = os.listdir(stories_dir)\n","    # make IO list file\n","    print(\"Making list of files to tokenize...\")\n","    with open(\"mapping_for_corenlp.txt\", \"w\") as f:\n","        for s in stories:\n","            if (not s.endswith('story')):\n","                continue\n","            f.write(\"%s\\n\" % (os.path.join(stories_dir, s)))\n","    command = ['java', 'edu.stanford.nlp.pipeline.StanfordCoreNLP', '-annotators', 'tokenize,ssplit',\n","               '-ssplit.newlineIsSentenceBreak', 'always', '-filelist', 'mapping_for_corenlp.txt', '-outputFormat',\n","               'json', '-outputDirectory', tokenized_stories_dir]\n","    print(\"Tokenizing %i files in %s and saving in %s...\" % (len(stories), stories_dir, tokenized_stories_dir))\n","    subprocess.call(command)\n","    print(\"Stanford CoreNLP Tokenizer has finished.\")\n","    os.remove(\"mapping_for_corenlp.txt\")\n","\n","    # Check that the tokenized stories directory contains the same number of files as the original directory\n","    num_orig = len(os.listdir(stories_dir))\n","    num_tokenized = len(os.listdir(tokenized_stories_dir))\n","    if num_orig != num_tokenized:\n","        raise Exception(\n","            \"The tokenized stories directory %s contains %i files, but it should contain the same number as %s (which has %i files). Was there an error during tokenization?\" % (\n","                tokenized_stories_dir, num_tokenized, stories_dir, num_orig))\n","    print(\"Successfully finished tokenizing %s to %s.\\n\" % (stories_dir, tokenized_stories_dir))\n","\n","def cal_rouge(evaluated_ngrams, reference_ngrams):\n","    reference_count = len(reference_ngrams)\n","    evaluated_count = len(evaluated_ngrams)\n","\n","    overlapping_ngrams = evaluated_ngrams.intersection(reference_ngrams)\n","    overlapping_count = len(overlapping_ngrams)\n","\n","    if evaluated_count == 0:\n","        precision = 0.0\n","    else:\n","        precision = overlapping_count / evaluated_count\n","\n","    if reference_count == 0:\n","        recall = 0.0\n","    else:\n","        recall = overlapping_count / reference_count\n","\n","    f1_score = 2.0 * ((precision * recall) / (precision + recall + 1e-8))\n","    return {\"f\": f1_score, \"p\": precision, \"r\": recall}\n","\n","\n","def greedy_selection(doc_sent_list, abstract_sent_list, summary_size):\n","    def _rouge_clean(s):\n","        return re.sub(r'[^a-zA-Z0-9 ]', '', s)\n","\n","    max_rouge = 0.0\n","    abstract = sum(abstract_sent_list, [])\n","    abstract = _rouge_clean(' '.join(abstract)).split()\n","    sents = [_rouge_clean(' '.join(s)).split() for s in doc_sent_list]\n","    evaluated_1grams = [_get_word_ngrams(1, [sent]) for sent in sents]\n","    reference_1grams = _get_word_ngrams(1, [abstract])\n","    evaluated_2grams = [_get_word_ngrams(2, [sent]) for sent in sents]\n","    reference_2grams = _get_word_ngrams(2, [abstract])\n","\n","    selected = []\n","    for s in range(summary_size):\n","        cur_max_rouge = max_rouge\n","        cur_id = -1\n","        for i in range(len(sents)):\n","            if (i in selected):\n","                continue\n","            c = selected + [i]\n","            candidates_1 = [evaluated_1grams[idx] for idx in c]\n","            candidates_1 = set.union(*map(set, candidates_1))\n","            candidates_2 = [evaluated_2grams[idx] for idx in c]\n","            candidates_2 = set.union(*map(set, candidates_2))\n","            rouge_1 = cal_rouge(candidates_1, reference_1grams)['f']\n","            rouge_2 = cal_rouge(candidates_2, reference_2grams)['f']\n","            rouge_score = rouge_1 + rouge_2\n","            if rouge_score > cur_max_rouge:\n","                cur_max_rouge = rouge_score\n","                cur_id = i\n","        if (cur_id == -1):\n","            return selected\n","        selected.append(cur_id)\n","        max_rouge = cur_max_rouge\n","\n","    return sorted(selected)\n","\n","\n","def hashhex(s):\n","    \"\"\"Returns a heximal formated SHA1 hash of the input string.\"\"\"\n","    h = hashlib.sha1()\n","    h.update(s.encode('utf-8'))\n","    return h.hexdigest()\n","\n","\n","class BertData():\n","    def __init__(self, args):\n","        self.args = args\n","        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n","\n","        self.sep_token = '[SEP]'\n","        self.cls_token = '[CLS]'\n","        self.pad_token = '[PAD]'\n","        self.tgt_bos = '[unused0]'\n","        self.tgt_eos = '[unused1]'\n","        self.tgt_sent_split = '[unused2]'\n","        self.sep_vid = self.tokenizer.vocab[self.sep_token]\n","        self.cls_vid = self.tokenizer.vocab[self.cls_token]\n","        self.pad_vid = self.tokenizer.vocab[self.pad_token]\n","\n","    def preprocess(self, src, tgt, sent_labels, use_bert_basic_tokenizer=False, is_test=False):\n","\n","        if ((not is_test) and len(src) == 0):\n","            return None\n","\n","        original_src_txt = [' '.join(s) for s in src]\n","\n","        idxs = [i for i, s in enumerate(src) if (len(s) > self.args.min_src_ntokens_per_sent)]\n","\n","        _sent_labels = [0] * len(src)\n","        for l in sent_labels:\n","            _sent_labels[l] = 1\n","\n","        src = [src[i][:self.args.max_src_ntokens_per_sent] for i in idxs]\n","        sent_labels = [_sent_labels[i] for i in idxs]\n","        src = src[:self.args.max_src_nsents]\n","        sent_labels = sent_labels[:self.args.max_src_nsents]\n","\n","        if ((not is_test) and len(src) < self.args.min_src_nsents):\n","            return None\n","\n","        src_txt = [' '.join(sent) for sent in src]\n","        text = ' {} {} '.format(self.sep_token, self.cls_token).join(src_txt)\n","\n","        src_subtokens = self.tokenizer.tokenize(text)\n","\n","        src_subtokens = [self.cls_token] + src_subtokens + [self.sep_token]\n","        src_subtoken_idxs = self.tokenizer.convert_tokens_to_ids(src_subtokens)\n","        _segs = [-1] + [i for i, t in enumerate(src_subtoken_idxs) if t == self.sep_vid]\n","        segs = [_segs[i] - _segs[i - 1] for i in range(1, len(_segs))]\n","        segments_ids = []\n","        for i, s in enumerate(segs):\n","            if (i % 2 == 0):\n","                segments_ids += s * [0]\n","            else:\n","                segments_ids += s * [1]\n","        cls_ids = [i for i, t in enumerate(src_subtoken_idxs) if t == self.cls_vid]\n","        sent_labels = sent_labels[:len(cls_ids)]\n","\n","        tgt_subtokens_str = '[unused0] ' + ' [unused2] '.join(\n","            [' '.join(self.tokenizer.tokenize(' '.join(tt), use_bert_basic_tokenizer=use_bert_basic_tokenizer)) for tt in tgt]) + ' [unused1]'\n","        tgt_subtoken = tgt_subtokens_str.split()[:self.args.max_tgt_ntokens]\n","        if ((not is_test) and len(tgt_subtoken) < self.args.min_tgt_ntokens):\n","            return None\n","\n","        tgt_subtoken_idxs = self.tokenizer.convert_tokens_to_ids(tgt_subtoken)\n","\n","        tgt_txt = '<q>'.join([' '.join(tt) for tt in tgt])\n","        src_txt = [original_src_txt[i] for i in idxs]\n","\n","        return src_subtoken_idxs, sent_labels, tgt_subtoken_idxs, segments_ids, cls_ids, src_txt, tgt_txt\n","\n","\n","def format_to_bert(args):\n","    if (args.dataset != ''):\n","        datasets = [args.dataset]\n","    else:\n","        datasets = ['train', 'valid', 'test']\n","    for corpus_type in datasets:\n","        a_lst = []\n","        for json_f in glob.glob(pjoin(args.raw_path, '*' + corpus_type + '.*.json')):\n","            real_name = json_f.split('/')[-1]\n","            a_lst.append((corpus_type, json_f, args, pjoin(args.save_path, real_name.replace('json', 'bert.pt'))))\n","        print(a_lst)\n","        pool = Pool(args.n_cpus)\n","        for d in pool.imap(_format_to_bert, a_lst):\n","            pass\n","\n","        pool.close()\n","        pool.join()\n","\n","\n","def _format_to_bert(params):\n","    corpus_type, json_file, args, save_file = params\n","    is_test = corpus_type == 'test'\n","    if (os.path.exists(save_file)):\n","        logger.info('Ignore %s' % save_file)\n","        return\n","\n","    bert = BertData(args)\n","\n","    logger.info('Processing %s' % json_file)\n","    jobs = json.load(open(json_file))\n","    datasets = []\n","    for d in jobs:\n","        source, tgt = d['src'], d['tgt']\n","\n","        sent_labels = greedy_selection(source[:args.max_src_nsents], tgt, 3)\n","        if (args.lower):\n","            source = [' '.join(s).lower().split() for s in source]\n","            tgt = [' '.join(s).lower().split() for s in tgt]\n","        b_data = bert.preprocess(source, tgt, sent_labels, use_bert_basic_tokenizer=args.use_bert_basic_tokenizer,\n","                                 is_test=is_test)\n","        # b_data = bert.preprocess(source, tgt, sent_labels, use_bert_basic_tokenizer=args.use_bert_basic_tokenizer)\n","\n","        if (b_data is None):\n","            continue\n","        src_subtoken_idxs, sent_labels, tgt_subtoken_idxs, segments_ids, cls_ids, src_txt, tgt_txt = b_data\n","        b_data_dict = {\"src\": src_subtoken_idxs, \"tgt\": tgt_subtoken_idxs,\n","                       \"src_sent_labels\": sent_labels, \"segs\": segments_ids, 'clss': cls_ids,\n","                       'src_txt': src_txt, \"tgt_txt\": tgt_txt}\n","        datasets.append(b_data_dict)\n","    logger.info('Processed instances %d' % len(datasets))\n","    logger.info('Saving to %s' % save_file)\n","    torch.save(datasets, save_file)\n","    datasets = []\n","    gc.collect()\n","\n","\n","def format_to_lines(args):\n","    corpus_mapping = {}\n","    for corpus_type in ['valid', 'test', 'train']:\n","        temp = []\n","        for line in open(pjoin(args.map_path, 'mapping_' + corpus_type + '.txt')):\n","            temp.append(hashhex(line.strip()))\n","        corpus_mapping[corpus_type] = {key.strip(): 1 for key in temp}\n","    train_files, valid_files, test_files = [], [], []\n","    for f in glob.glob(pjoin(args.raw_path, '*.json')):\n","        real_name = f.split('/')[-1].split('.')[0]\n","        if (real_name in corpus_mapping['valid']):\n","            valid_files.append(f)\n","        elif (real_name in corpus_mapping['test']):\n","            test_files.append(f)\n","        elif (real_name in corpus_mapping['train']):\n","            train_files.append(f)\n","        # else:\n","        #     train_files.append(f)\n","\n","    corpora = {'train': train_files, 'valid': valid_files, 'test': test_files}\n","    for corpus_type in ['train', 'valid', 'test']:\n","        a_lst = [(f, args) for f in corpora[corpus_type]]\n","        pool = Pool(args.n_cpus)\n","        dataset = []\n","        p_ct = 0\n","        for d in pool.imap_unordered(_format_to_lines, a_lst):\n","            dataset.append(d)\n","            if (len(dataset) > args.shard_size):\n","                pt_file = \"{:s}.{:s}.{:d}.json\".format(args.save_path, corpus_type, p_ct)\n","                with open(pt_file, 'w') as save:\n","                    # save.write('\\n'.join(dataset))\n","                    save.write(json.dumps(dataset))\n","                    p_ct += 1\n","                    dataset = []\n","\n","        pool.close()\n","        pool.join()\n","        if (len(dataset) > 0):\n","            pt_file = \"{:s}.{:s}.{:d}.json\".format(args.save_path, corpus_type, p_ct)\n","            with open(pt_file, 'w') as save:\n","                # save.write('\\n'.join(dataset))\n","                save.write(json.dumps(dataset))\n","                p_ct += 1\n","                dataset = []\n","\n","\n","def _format_to_lines(params):\n","    f, args = params\n","    print(f)\n","    source, tgt = load_json(f, args.lower)\n","    return {'src': source, 'tgt': tgt}\n","\n","\n","\n","\n","def format_xsum_to_lines(args):\n","    if (args.dataset != ''):\n","        datasets = [args.dataset]\n","    else:\n","        datasets = ['train', 'test', 'valid']\n","\n","    corpus_mapping = json.load(open(pjoin(args.raw_path, 'XSum-TRAINING-DEV-TEST-SPLIT-90-5-5.json')))\n","\n","    for corpus_type in datasets:\n","        mapped_fnames = corpus_mapping[corpus_type]\n","        root_src = pjoin(args.raw_path, 'restbody')\n","        root_tgt = pjoin(args.raw_path, 'firstsentence')\n","        # realnames = [fname.split('.')[0] for fname in os.listdir(root_src)]\n","        realnames = mapped_fnames\n","\n","        a_lst = [(root_src, root_tgt, n) for n in realnames]\n","        pool = Pool(args.n_cpus)\n","        dataset = []\n","        p_ct = 0\n","        for d in pool.imap_unordered(_format_xsum_to_lines, a_lst):\n","            if (d is None):\n","                continue\n","            dataset.append(d)\n","            if (len(dataset) > args.shard_size):\n","                pt_file = \"{:s}.{:s}.{:d}.json\".format(args.save_path, corpus_type, p_ct)\n","                with open(pt_file, 'w') as save:\n","                    save.write(json.dumps(dataset))\n","                    p_ct += 1\n","                    dataset = []\n","\n","        pool.close()\n","        pool.join()\n","        if (len(dataset) > 0):\n","            pt_file = \"{:s}.{:s}.{:d}.json\".format(args.save_path, corpus_type, p_ct)\n","            with open(pt_file, 'w') as save:\n","                save.write(json.dumps(dataset))\n","                p_ct += 1\n","                dataset = []\n","\n","\n","def _format_xsum_to_lines(params):\n","    src_path, root_tgt, name = params\n","    f_src = pjoin(src_path, name + '.restbody')\n","    f_tgt = pjoin(root_tgt, name + '.fs')\n","    if (os.path.exists(f_src) and os.path.exists(f_tgt)):\n","        print(name)\n","        source = []\n","        for sent in open(f_src):\n","            source.append(sent.split())\n","        tgt = []\n","        for sent in open(f_tgt):\n","            tgt.append(sent.split())\n","        return {'src': source, 'tgt': tgt}\n","    return None"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K5H1En4WavEA"},"source":["# stopwords = pkgutil.get_data(__package__, 'smart_common_words.txt')\n","# stopwords = stopwords.decode('ascii').split('\\n')\n","# stopwords = {key.strip(): 1 for key in stopwords}\n","\n","\n","def _get_ngrams(n, text):\n","    \"\"\"Calcualtes n-grams.\n","\n","    Args:\n","      n: which n-grams to calculate\n","      text: An array of tokens\n","\n","    Returns:\n","      A set of n-grams\n","    \"\"\"\n","    ngram_set = set()\n","    text_length = len(text)\n","    max_index_ngram_start = text_length - n\n","    for i in range(max_index_ngram_start + 1):\n","        ngram_set.add(tuple(text[i:i + n]))\n","    return ngram_set\n","\n","\n","def _get_word_ngrams(n, sentences):\n","    \"\"\"Calculates word n-grams for multiple sentences.\n","    \"\"\"\n","    assert len(sentences) > 0\n","    assert n > 0\n","\n","    # words = _split_into_words(sentences)\n","\n","    words = sum(sentences, [])\n","    # words = [w for w in words if w not in stopwords]\n","    return _get_ngrams(n, words)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H2WkReQQazoW"},"source":["#encoding=utf-8\n","\n","\n","import argparse\n","import time\n","\n","from others.logging import init_logger\n","from prepro import data_builder\n","\n","\n","def do_format_to_lines(args):\n","    print(time.clock())\n","    custom_format_to_lines(args)\n","    print(time.clock())\n","\n","def do_format_to_bert(args):\n","    print(time.clock())\n","    format_to_bert(args)\n","    print(time.clock())\n","\n","\n","\n","def do_format_xsum_to_lines(args):\n","    print(time.clock())\n","    data_builder.format_xsum_to_lines(args)\n","    print(time.clock())\n","\n","def do_tokenize(args):\n","    print(time.clock())\n","    data_builder.tokenize(args)\n","    print(time.clock())\n","\n","\n","def str2bool(v):\n","    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n","        return True\n","    elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n","        return False\n","    else:\n","        raise argparse.ArgumentTypeError('Boolean value expected.')\n","\n","\n","\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ny-H876ccnI2"},"source":["import os\n","os.environ['CLASSPATH'] = \"/content/drive/My Drive/Colab Notebooks/Mestrado/Extractive Summarization/stanford-corenlp-4.2.0/stanford-corenlp-4.2.0.jar\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VLUqQ85zctST","executionInfo":{"status":"ok","timestamp":1612835034521,"user_tz":180,"elapsed":1754,"user":{"displayName":"Cinthia Mikaela de Souza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSYWVyWfXKPRe-m_hW9EaymViE56Sd6-54Bvh6=s64","userId":"06359001126903823254"}},"outputId":"7f9336aa-ba5f-43e4-faba-45454bd069d3"},"source":["import time\n","import sys\n","\n","class args:\n","    pass\n","\n","args.mode='tokenize'\n","args.oracle_mode='greedy'\n","args.map_path='../urls'\n","args.save_path='../merged_stories_tokenized/text'\n","args.raw_path='../../BertSum/raw_stories/text'\n","args.shard_size=2000\n","args.min_nsents=3\n","args.max_nsents=100\n","args.min_src_ntokens=5\n","args.max_src_ntokens=200\n","args.lower=True\n","args.log_file='../../logs/cnndm.log'\n","args.dataset='test'\n","args.n_cpus=2\n","\n","do_tokenize(args)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["22.164634\n","Preparing to tokenize /content/drive/My Drive/Colab Notebooks/Mestrado/Extractive Summarization/BertSum/raw_stories/text to /content/drive/My Drive/Colab Notebooks/Mestrado/Extractive Summarization/PreSumm/merged_stories_tokenized/text...\n","Making list of files to tokenize...\n","Tokenizing 9 files in /content/drive/My Drive/Colab Notebooks/Mestrado/Extractive Summarization/BertSum/raw_stories/text and saving in /content/drive/My Drive/Colab Notebooks/Mestrado/Extractive Summarization/PreSumm/merged_stories_tokenized/text...\n","Stanford CoreNLP Tokenizer has finished.\n","Successfully finished tokenizing /content/drive/My Drive/Colab Notebooks/Mestrado/Extractive Summarization/BertSum/raw_stories/text to /content/drive/My Drive/Colab Notebooks/Mestrado/Extractive Summarization/PreSumm/merged_stories_tokenized/text.\n","\n","22.173695\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WfPgzM4Tc-KY","executionInfo":{"status":"ok","timestamp":1612835664983,"user_tz":180,"elapsed":1297,"user":{"displayName":"Cinthia Mikaela de Souza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSYWVyWfXKPRe-m_hW9EaymViE56Sd6-54Bvh6=s64","userId":"06359001126903823254"}},"outputId":"06910980-3226-41dc-a4be-fb7dafeaf313"},"source":["class args:\n","    pass\n","\n","args.mode='tokenize'\n","args.oracle_mode='greedy'\n","args.map_path='../urls'\n","args.save_path='../merged_stories_tokenized/summary'\n","args.raw_path='../../BertSum/raw_stories/summary'\n","args.shard_size=2000\n","args.min_nsents=3\n","args.max_nsents=100\n","args.min_src_ntokens=5\n","args.max_src_ntokens=200\n","args.lower=True\n","args.log_file='../../logs/cnndm.log'\n","args.dataset='test'\n","args.n_cpus=2\n","\n","do_tokenize(args)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["23.811014\n","Preparing to tokenize /content/drive/My Drive/Colab Notebooks/Mestrado/Extractive Summarization/BertSum/raw_stories/summary to /content/drive/My Drive/Colab Notebooks/Mestrado/Extractive Summarization/PreSumm/merged_stories_tokenized/summary...\n","Making list of files to tokenize...\n","Tokenizing 9 files in /content/drive/My Drive/Colab Notebooks/Mestrado/Extractive Summarization/BertSum/raw_stories/summary and saving in /content/drive/My Drive/Colab Notebooks/Mestrado/Extractive Summarization/PreSumm/merged_stories_tokenized/summary...\n","Stanford CoreNLP Tokenizer has finished.\n","Successfully finished tokenizing /content/drive/My Drive/Colab Notebooks/Mestrado/Extractive Summarization/BertSum/raw_stories/summary to /content/drive/My Drive/Colab Notebooks/Mestrado/Extractive Summarization/PreSumm/merged_stories_tokenized/summary.\n","\n","23.822101\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dW3WdteJdvNg"},"source":["def custom_format_to_lines(args):\n","    corpus_mapping = {}\n","    files = []\n","\n","    print('aq')\n","    for f in glob.glob(pjoin(args.raw_path, '*.json')):\n","        files.append(f)\n","    \n","    corpora = {'test': files}\n","\n","    for corpus_type in ['test']:\n","        a_lst = [(f, args) for f in corpora[corpus_type]]\n","        pool = Pool(args.n_cpus)\n","        dataset = []\n","        p_ct = 0\n","        for d in pool.imap_unordered(_format_to_lines, a_lst):\n","            \n","            dataset.append(d)\n","            pt_file = \"{:s}.{:s}.{:d}.json\".format(args.save_path, corpus_type, p_ct)\n","            \n","            with open(pt_file, 'w') as save:\n","                # save.write('\\n'.join(dataset))\n","                save.write(json.dumps(dataset))\n","                p_ct += 1\n","                dataset = []\n","\n","        pool.close()\n","        pool.join()\n","        if (len(dataset) > 0):\n","            pt_file = \"{:s}.{:s}.{:d}.json\".format(args.save_path, corpus_type, p_ct)\n","            with open(pt_file, 'w') as save:\n","                # save.write('\\n'.join(dataset))\n","                save.write(json.dumps(dataset))\n","                p_ct += 1\n","                dataset = []\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kG2qXZpwdJb4","executionInfo":{"status":"ok","timestamp":1612835679027,"user_tz":180,"elapsed":794,"user":{"displayName":"Cinthia Mikaela de Souza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSYWVyWfXKPRe-m_hW9EaymViE56Sd6-54Bvh6=s64","userId":"06359001126903823254"}},"outputId":"025dbd5d-b557-482a-db5c-3b405cc5cca0"},"source":["import time\n","import sys\n","\n","class args:\n","    pass\n","\n","args.mode='do_format_to_lines'\n","args.oracle_mode='greedy'\n","args.map_path='../urls'\n","args.save_path='../json_data/text'\n","args.raw_path='../merged_stories_tokenized/text'\n","args.shard_size=2000\n","args.min_nsents=3\n","args.max_nsents=100\n","args.min_src_ntokens=5\n","args.max_src_ntokens=200\n","args.lower=True\n","args.log_file='../../logs/cnndm.log'\n","args.use_bert_basic_tokenizer=False\n","args.dataset='test'\n","args.n_cpus=2\n","\n","do_format_to_lines(args)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["23.887765\n","aq\n","../merged_stories_tokenized/text/plosone_PMC3005250.story.json\n","../merged_stories_tokenized/text/plosone_PMC3006677.story.json\n","../merged_stories_tokenized/text/plosone_PMC3010241.story.json\n","../merged_stories_tokenized/text/plosone_PMC3012355.story.json\n","../merged_stories_tokenized/text/plosone_PMC3012387.story.json\n","../merged_stories_tokenized/text/plosone_PMC3003435.story.json\n","../merged_stories_tokenized/text/plosone_PMC3005290.story.json\n","../merged_stories_tokenized/text/plosone_PMC3003437.story.json\n","../merged_stories_tokenized/text/plosone_PMC3016643.story.json\n","23.926963\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Iq9U_cbpbUlY","executionInfo":{"status":"ok","timestamp":1612835682254,"user_tz":180,"elapsed":632,"user":{"displayName":"Cinthia Mikaela de Souza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSYWVyWfXKPRe-m_hW9EaymViE56Sd6-54Bvh6=s64","userId":"06359001126903823254"}},"outputId":"3d043422-ec77-4281-c137-e454f4a1f1a1"},"source":["import time\n","import sys\n","\n","class args:\n","    pass\n","\n","args.mode='do_format_to_lines'\n","args.oracle_mode='greedy'\n","args.map_path='../urls'\n","args.save_path='../json_data/text'\n","args.raw_path='../merged_stories_tokenized/text'\n","args.shard_size=2000\n","args.min_nsents=3\n","args.max_nsents=100\n","args.min_src_ntokens=5\n","args.max_src_ntokens=200\n","args.lower=True\n","args.log_file='../../logs/cnndm.log'\n","args.dataset='test'\n","args.n_cpus=2\n","\n","\n","do_format_to_lines(args)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["23.948043\n","aq\n","../merged_stories_tokenized/text/plosone_PMC3005250.story.json\n","../merged_stories_tokenized/text/plosone_PMC3006677.story.json\n","../merged_stories_tokenized/text/plosone_PMC3010241.story.json\n","../merged_stories_tokenized/text/plosone_PMC3012355.story.json\n","../merged_stories_tokenized/text/plosone_PMC3012387.story.json\n","../merged_stories_tokenized/text/plosone_PMC3003435.story.json\n","../merged_stories_tokenized/text/plosone_PMC3005290.story.json\n","../merged_stories_tokenized/text/plosone_PMC3016643.story.json\n","../merged_stories_tokenized/text/plosone_PMC3003437.story.json\n","23.987482\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SLQlWCNyeSyB","executionInfo":{"status":"ok","timestamp":1612835686875,"user_tz":180,"elapsed":1633,"user":{"displayName":"Cinthia Mikaela de Souza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSYWVyWfXKPRe-m_hW9EaymViE56Sd6-54Bvh6=s64","userId":"06359001126903823254"}},"outputId":"0dc971c2-ea3d-4696-efeb-5e1198e84d93"},"source":["class args:\n","    pass\n","\n","args.mode='do_format_to_bert'\n","args.oracle_mode='greedy'\n","args.map_path='../urls'\n","args.save_path='../bert_data'\n","args.raw_path='../json_data'\n","args.shard_size=2000\n","args.min_src_nsents=3\n","args.max_src_nsents=100\n","args.min_src_ntokens_per_sent=5\n","args.max_src_ntokens_per_sent=200\n","args.lower=True\n","args.log_file='../../logs/cnndm.log'\n","args.use_bert_basic_tokenizer=False\n","args.dataset='test'\n","args.n_cpus=2\n","args.min_tgt_ntokens=5\n","args.max_tgt_ntokens=500\n","\n","\n","do_format_to_bert(args)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["24.009095\n","[('test', '../json_data/text.test.0.json', <class '__main__.args'>, '../bert_data/text.test.0.bert.pt'), ('test', '../json_data/text.test.1.json', <class '__main__.args'>, '../bert_data/text.test.1.bert.pt'), ('test', '../json_data/text.test.2.json', <class '__main__.args'>, '../bert_data/text.test.2.bert.pt'), ('test', '../json_data/text.test.3.json', <class '__main__.args'>, '../bert_data/text.test.3.bert.pt'), ('test', '../json_data/text.test.4.json', <class '__main__.args'>, '../bert_data/text.test.4.bert.pt'), ('test', '../json_data/text.test.5.json', <class '__main__.args'>, '../bert_data/text.test.5.bert.pt'), ('test', '../json_data/text.test.6.json', <class '__main__.args'>, '../bert_data/text.test.6.bert.pt'), ('test', '../json_data/text.test.7.json', <class '__main__.args'>, '../bert_data/text.test.7.bert.pt'), ('test', '../json_data/text.test.8.json', <class '__main__.args'>, '../bert_data/text.test.8.bert.pt')]\n","24.041746\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"R2UkebsygrQU"},"source":["# Validation"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QEv-m0eygtbN","executionInfo":{"status":"ok","timestamp":1612836146084,"user_tz":180,"elapsed":746,"user":{"displayName":"Cinthia Mikaela de Souza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSYWVyWfXKPRe-m_hW9EaymViE56Sd6-54Bvh6=s64","userId":"06359001126903823254"}},"outputId":"1fab69ae-61c4-4c6b-ae08-efa6fe04f934"},"source":["cd /content/drive/My Drive/Colab Notebooks"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"S30AkDPwguIo"},"source":["import os\n","import numpy as np\n","import glob\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R2WxhxWWgwtz","executionInfo":{"status":"ok","timestamp":1612836283196,"user_tz":180,"elapsed":134783,"user":{"displayName":"Cinthia Mikaela de Souza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSYWVyWfXKPRe-m_hW9EaymViE56Sd6-54Bvh6=s64","userId":"06359001126903823254"}},"outputId":"51968f44-2cc3-44ae-97f6-c3b47fabf690"},"source":["\n","'''\n","!git clone https://github.com/google-research/bleurt.git\n","os.chdir('bleurt')\n","!pip install .\n","from bleurt import score\n","tf.compat.v1.flags.DEFINE_string('f','','')\n","checkpoint = \"bleurt/test_checkpoint\"\n","bleurt = score.BleurtScorer(checkpoint)\n","'''\n","\n","#!git clone https://github.com/wl-research/nubia.git\n","os.chdir('nubia')\n","!pip install -r requirements.txt\n","from nubia import Nubia\n","nubia = Nubia()\n","\n","!pip install sumeval\n","!python -m spacy download en"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (1.7.1)\n","Requirement already satisfied: fairseq in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (0.10.2)\n","Requirement already satisfied: pytorch-transformers in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (1.2.0)\n","Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (1.19.5)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (1.0.0)\n","Requirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 6)) (0.22.2.post1)\n","Requirement already satisfied: wget in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 7)) (3.2)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (0.8)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (3.7.4.3)\n","Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from fairseq->-r requirements.txt (line 2)) (2019.12.20)\n","Requirement already satisfied: hydra-core in /usr/local/lib/python3.6/dist-packages (from fairseq->-r requirements.txt (line 2)) (1.0.6)\n","Requirement already satisfied: cffi in /usr/local/lib/python3.6/dist-packages (from fairseq->-r requirements.txt (line 2)) (1.14.4)\n","Requirement already satisfied: sacrebleu>=1.4.12 in /usr/local/lib/python3.6/dist-packages (from fairseq->-r requirements.txt (line 2)) (1.5.0)\n","Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from fairseq->-r requirements.txt (line 2)) (0.29.21)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from fairseq->-r requirements.txt (line 2)) (4.41.1)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers->-r requirements.txt (line 3)) (1.17.4)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers->-r requirements.txt (line 3)) (0.0.43)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers->-r requirements.txt (line 3)) (2.23.0)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers->-r requirements.txt (line 3)) (0.1.95)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.22.2->-r requirements.txt (line 6)) (1.4.1)\n","Requirement already satisfied: omegaconf<2.1,>=2.0.5 in /usr/local/lib/python3.6/dist-packages (from hydra-core->fairseq->-r requirements.txt (line 2)) (2.0.6)\n","Requirement already satisfied: antlr4-python3-runtime==4.8 in /usr/local/lib/python3.6/dist-packages (from hydra-core->fairseq->-r requirements.txt (line 2)) (4.8)\n","Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.6/dist-packages (from hydra-core->fairseq->-r requirements.txt (line 2)) (5.1.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi->fairseq->-r requirements.txt (line 2)) (2.20)\n","Requirement already satisfied: portalocker in /usr/local/lib/python3.6/dist-packages (from sacrebleu>=1.4.12->fairseq->-r requirements.txt (line 2)) (2.2.1)\n","Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers->-r requirements.txt (line 3)) (0.3.4)\n","Requirement already satisfied: botocore<1.21.0,>=1.20.4 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers->-r requirements.txt (line 3)) (1.20.4)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers->-r requirements.txt (line 3)) (0.10.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers->-r requirements.txt (line 3)) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers->-r requirements.txt (line 3)) (1.15.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers->-r requirements.txt (line 3)) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers->-r requirements.txt (line 3)) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers->-r requirements.txt (line 3)) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers->-r requirements.txt (line 3)) (3.0.4)\n","Requirement already satisfied: PyYAML>=5.1.* in /usr/local/lib/python3.6/dist-packages (from omegaconf<2.1,>=2.0.5->hydra-core->fairseq->-r requirements.txt (line 2)) (5.4.1)\n","Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-resources; python_version < \"3.9\"->hydra-core->fairseq->-r requirements.txt (line 2)) (3.4.0)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.21.0,>=1.20.4->boto3->pytorch-transformers->-r requirements.txt (line 3)) (2.8.1)\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 10010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n","  return torch._C._cuda_getDeviceCount() > 0\n","1042301B [00:00, 2758246.71B/s]\n","456318B [00:00, 1525230.02B/s]\n","100%|██████████| 1042301/1042301 [00:00<00:00, 25225481.25B/s]\n","100%|██████████| 456318/456318 [00:00<00:00, 19053812.51B/s]\n","100%|██████████| 665/665 [00:00<00:00, 430035.79B/s]\n","100%|██████████| 548118077/548118077 [00:09<00:00, 58210676.20B/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Collecting sumeval\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e6/87/bfc0f9397b9421305863edfdd2dbea637e47204976cb5473535c856338f4/sumeval-0.2.2.tar.gz (80kB)\n","\r\u001b[K     |████                            | 10kB 23.8MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 20kB 30.2MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 30kB 22.4MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 40kB 21.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 51kB 23.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 61kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 71kB 18.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 8.8MB/s \n","\u001b[?25hRequirement already satisfied: plac>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from sumeval) (1.1.3)\n","Requirement already satisfied: sacrebleu>=1.3.2 in /usr/local/lib/python3.6/dist-packages (from sumeval) (1.5.0)\n","Requirement already satisfied: portalocker in /usr/local/lib/python3.6/dist-packages (from sacrebleu>=1.3.2->sumeval) (2.2.1)\n","Building wheels for collected packages: sumeval\n","  Building wheel for sumeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sumeval: filename=sumeval-0.2.2-cp36-none-any.whl size=54537 sha256=26eb60a37c105de2cfd3d1c2536bd0d3f8d16e435818bf68e63fd4cffe53bc9d\n","  Stored in directory: /root/.cache/pip/wheels/7b/6f/57/19ceecab21445c88f3c565735fa1887b4cd18d340c972eb445\n","Successfully built sumeval\n","Installing collected packages: sumeval\n","Successfully installed sumeval-0.2.2\n","Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n","Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (53.0.0)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n","Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the model via spacy.load('en_core_web_sm')\n","\u001b[38;5;2m✔ Linking successful\u001b[0m\n","/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n","/usr/local/lib/python3.6/dist-packages/spacy/data/en\n","You can now load the model via spacy.load('en')\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8QK8WjV-gy_T"},"source":["from nltk.tokenize import sent_tokenize, word_tokenize\n","from sumeval.metrics.rouge import RougeCalculator\n","from xml.etree import ElementTree\n","from xml.dom import minidom\n","from functools import reduce\n","from xml.etree.ElementTree import Element, SubElement, Comment\n","\n","\n","def eval(\n","    reference_summary, model_summary, metrics=[\"ROUGE_1\", \"ROUGE_2\", \"ROUGE_L\", \"NUBIA\", \"BLEURT\"]):\n","\n","    rouge = RougeCalculator(stopwords=True, lang=\"en\")\n","\n","    if(\"ROUGE_1\" in metrics):\n","      rouge_1 = rouge.rouge_n( summary=model_summary, references=reference_summary, n=1)\n","    else:\n","      rouge_1 = None\n","\n","    if(\"ROUGE_2\" in metrics):\n","      rouge_2 = rouge.rouge_n(summary=model_summary,references=[reference_summary],n=2)\n","    else:\n","      rouge_2 = None\n","\n","    if(\"ROUGE_L\" in metrics):\n","      rouge_l = rouge.rouge_l( summary=model_summary,references=[reference_summary])\n","    else:\n","      rouge_l = None\n","\n","    if(\"NUBIA\" in metrics):\n","      nubia_score = nubia.score(reference_summary, model_summary)\n","    else:\n","      nubia_score =  None\n","\n","    if(\"BLEURT\" in metrics):\n","      bleurt_score = scorer.score([reference_summary], [model_summary])\n","      assert type(bleurt_score) == list and len(bleurt_score) == 1\n","    else:\n","      bleurt_score = None\n","\n","    return rouge_1, rouge_2,rouge_l, nubia_score, bleurt_score\n","\n","def prettify(elem):\n","      \"\"\"Return a pretty-printed XML string for the Element.\n","      \"\"\"\n","      rough_string = ElementTree.tostring(elem, 'utf-8')\n","      reparsed = minidom.parseString(rough_string)\n","      return reparsed.toprettyxml(indent=\"  \")\n","  \n","def create_report_valid(\n","    summary_array, references_summary, article, name_file,\n","     metrics=[\"ROUGE_1\", \"ROUGE_2\", \"ROUGE_L\", \"NUBIA\", \"BLEURT\"]):\n","\n","  rouge_1_arr  = []\n","  rouge_2_arr  = []\n","  rouge_L_arr  = []\n","  NUBIA_arr = []\n","  bleurt_arr = []\n","\n","  top = Element('ZakSum')\n","\n","  comment = Comment('Generated by Amr Zaki')\n","  top.append(comment)\n","\n","  i=0\n","  for summ in summary_array:\n","\n","      \n","      example = SubElement(top, 'example')\n","      article_element   = SubElement(example, 'article')\n","      article_element.text = article[i]\n","  \n","      reference_element = SubElement(example, 'reference')\n","      reference_element.text = references_summary[i]\n","  \n","      summary_element   = SubElement(example, 'summary')\n","      summary_element.text = summ\n","\n","      if(len(summ) != 0):\n","        rouge_1, rouge_2, rouge_L, nubia_score, bleurt_score = eval(references_summary[i],summ, metrics=metrics )\n","      else: \n","        rouge_1 = rouge_2 = rouge_L = nubia_score, bleurt_score = 0\n","  \n","      eval_element = SubElement(example, 'eval')\n","      if(rouge_1 != None):\n","        ROUGE_1_element  = SubElement(eval_element, 'ROUGE_1' , {'score':str(rouge_1)})\n","        rouge_1_arr.append(rouge_1) \n","      if(rouge_2 != None):\n","        ROUGE_2_element  = SubElement(eval_element, 'ROUGE_2' , {'score':str(rouge_2)})\n","        rouge_2_arr.append(rouge_2)\n","      if(rouge_L != None):\n","        ROUGE_L_element  = SubElement(eval_element, 'ROUGE_l' , {'score':str(rouge_L)})\n","        rouge_L_arr.append(rouge_L)\n","      if(nubia_score != None): \n","        NUBIA_element =  SubElement(eval_element,'NUBIA', {'score':str(nubia_score)})\n","        NUBIA_arr.append(nubia_score)\n","      if(bleurt_score != None): \n","        BLEURT_element =  SubElement(eval_element,'BLEURT', {'score':str(bleurt_score[0])})\n","        bleurt_arr.append(bleurt_score[0])\n","  \n","      i+=1\n","\n","  if(rouge_1_arr != []): top.set('rouge_1', str(np.mean(rouge_1_arr)))\n","  if(rouge_2_arr != []): top.set('rouge_2', str(np.mean(rouge_2_arr)))\n","  if(rouge_L_arr != []): top.set('rouge_L', str(np.mean(rouge_L_arr)))\n","  if(NUBIA_arr != []): top.set('NUBIA', str(np.mean(NUBIA_arr)))\n","  if(bleurt_arr != []):top.set('BLEURT', str(np.mean(bleurt_arr)))\n","\n","\n","  with open(name_file, \"w+\") as f:\n","    print(prettify(top), file=f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CehlF6eQg0gB","executionInfo":{"status":"ok","timestamp":1612836772876,"user_tz":180,"elapsed":708,"user":{"displayName":"Cinthia Mikaela de Souza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSYWVyWfXKPRe-m_hW9EaymViE56Sd6-54Bvh6=s64","userId":"06359001126903823254"}},"outputId":"b45d4422-15be-495e-b9bd-7983848f5f51"},"source":["cd /content/drive/My Drive/Colab Notebooks/Mestrado/Extractive Summarization/PreSumm/"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/Mestrado/Extractive Summarization/PreSumm\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"55-uiTzIg3Gi","executionInfo":{"status":"ok","timestamp":1612836912527,"user_tz":180,"elapsed":791,"user":{"displayName":"Cinthia Mikaela de Souza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSYWVyWfXKPRe-m_hW9EaymViE56Sd6-54Bvh6=s64","userId":"06359001126903823254"}},"outputId":"6b53d0ce-4c52-4b01-fafd-984da2a8665b"},"source":["candidates = open('results/cnndm_step0.candidate').readlines()\n","\n","print(len(candidates))\n","\n","name_files = glob.glob(\"/content/drive/My Drive/Colab Notebooks/Mestrado/Extractive Summarization/BertSum/raw_stories/summary/*.story\")\n","\n","references=[]\n","for i in name_files:\n","    references.append(open(i).read())\n","\n","print(len(references))\n","\n","name_files = glob.glob(\"/content/drive/My Drive/Colab Notebooks/Mestrado/Extractive Summarization/BertSum/raw_stories/text/*.story\")\n","texts=[]\n","for i in name_files:\n","    texts.append(open(i).read())\n","\n","print(len(texts))\n","\n","metrics=[\"ROUGE_1\", \"ROUGE_2\", \"ROUGE_L\"]\n","create_report_valid(\n","    candidates, references, texts, name_file=\"presumm_validation.xml\" , metrics=metrics)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["9\n","9\n","9\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uZ8L_WESje_J","executionInfo":{"status":"ok","timestamp":1612836901495,"user_tz":180,"elapsed":690,"user":{"displayName":"Cinthia Mikaela de Souza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSYWVyWfXKPRe-m_hW9EaymViE56Sd6-54Bvh6=s64","userId":"06359001126903823254"}},"outputId":"0dc6ccbc-b179-491a-8bcf-fc6354298a66"},"source":["references"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<function TextIOWrapper.read>,\n"," <function TextIOWrapper.read>,\n"," <function TextIOWrapper.read>,\n"," <function TextIOWrapper.read>,\n"," <function TextIOWrapper.read>,\n"," <function TextIOWrapper.read>,\n"," <function TextIOWrapper.read>,\n"," <function TextIOWrapper.read>,\n"," <function TextIOWrapper.read>]"]},"metadata":{"tags":[]},"execution_count":12}]}]}