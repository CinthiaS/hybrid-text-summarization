{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "from sumy.summarizers.lex_rank import LexRankSummarizer as SummarizerLex\n",
    "from sumy.summarizers.sum_basic import SumBasicSummarizer as SummarizerSumBasic\n",
    "from sumy.summarizers.text_rank import TextRankSummarizer  as SummarizerTextrank\n",
    "from sumy.nlp.stemmers import Stemmer\n",
    "from sumy.utils import get_stop_words\n",
    "\n",
    "\n",
    "LANGUAGE = \"english\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, '../src')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "import rouge"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "def summarization_one_file(summarizer, parser, SENTENCES_COUNT):\n",
    "\n",
    "    sentences = []\n",
    "    for sentence in summarizer(parser.document, SENTENCES_COUNT):\n",
    "        sentences.append(str(sentence))\n",
    "\n",
    "    return sentences\n",
    "\n",
    "def summarization_all_files(patents, model='lex', SENTENCES_COUNT=3):\n",
    "\n",
    "    stemmer = Stemmer(LANGUAGE)\n",
    "\n",
    "    if model == 'lex':\n",
    "\n",
    "        summarizer = SummarizerLex(stemmer)\n",
    "        summarizer.stop_words = get_stop_words(LANGUAGE)\n",
    "    \n",
    "    elif model == 'textrank':\n",
    "\n",
    "        summarizer = SummarizerTextrank(stemmer)\n",
    "        summarizer.stop_words = get_stop_words(LANGUAGE)\n",
    "\n",
    "    elif model == 'sumbasic':\n",
    "\n",
    "        summarizer = SummarizerSumBasic(stemmer)\n",
    "        summarizer.stop_words = get_stop_words(LANGUAGE)\n",
    "\n",
    "\n",
    "    summaries = []\n",
    "\n",
    "    f = open(\"{}_summ.txt\".format(model), 'w')\n",
    "    for text in patents:\n",
    "\n",
    "        parser = PlaintextParser(text, Tokenizer(LANGUAGE))\n",
    "        summ = summarization_one_file(summarizer, parser, SENTENCES_COUNT=SENTENCES_COUNT)\n",
    "        summ = ' '.join(summ)\n",
    "        summaries.append(summ)\n",
    "        f.write(summ)\n",
    "\n",
    "    f.close()\n",
    "\n",
    "    return summaries"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "def evaluation(candidates, references, sources, algorithm):\n",
    "\n",
    "    metrics=[\"ROUGE_1\", \"ROUGE_2\", \"ROUGE_L\", \"BLEU\"]\n",
    "    rouge.create_report_valid(\n",
    "            candidates, references, sources,\n",
    "            name_file=\"../validation/{}.xml\".format(algorithm),\n",
    "            metrics=metrics)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "source": [
    "patents = open(\"../sumdata/abstract.valid.pp.txt\").readlines()\n",
    "len(patents)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "8307"
      ]
     },
     "metadata": {},
     "execution_count": 111
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "source": [
    "titles = open(\"../sumdata/title.valid.pp.txt\").readlines()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TextRank"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "source": [
    "candidates_text = summarization_all_files(patents, model='textrank', SENTENCES_COUNT=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "source": [
    "evaluation(candidates_text, titles, patents, 'textrank')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SumBasic"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "source": [
    "candidates_sumbasic = summarization_all_files(patents, model='sumbasic', SENTENCES_COUNT=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "source": [
    "evaluation(candidates_sumbasic, titles, patents, 'sumbasic')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "doc = nlp(candidates_lex[0])\n",
    "\n",
    "list_pos = []\n",
    "for token in doc:\n",
    "    list_pos.append(token.pos_)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "source": [
    "e1 = open(\"../hybrid_results/e1.txt\").readlines()\n",
    "len(e1)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "8306"
      ]
     },
     "metadata": {},
     "execution_count": 120
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "sw = stopwords.words('english')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "source": [
    "def filter_summaries(candidates):\n",
    "\n",
    "    format_candidates = []\n",
    "\n",
    "    for candidate in candidates:\n",
    "\n",
    "        doc = nlp(candidate)\n",
    "\n",
    "        list_pos = []\n",
    "        for token in doc:\n",
    "            list_pos.append(token.pos_)\n",
    "\n",
    "        words = candidate.split(\" \")\n",
    "\n",
    "        sentence_ws = []\n",
    "        sentence = []\n",
    "        cont = 0\n",
    "\n",
    "        for i in words:\n",
    "\n",
    "            if (not i in sw) and (len(sentence) <= 15):\n",
    "                sentence.append(i)\n",
    "            if (len(sentence) <= 15):\n",
    "                sentence_ws.append(i)\n",
    "\n",
    "        if (list_pos[len(sentence_ws)-1] != \"NOUN\"):\n",
    "            for i in range(len(sentence_ws)):\n",
    "                if list_pos[len(sentence_ws)-1 - i] != \"NOUN\":\n",
    "                    cont+=1\n",
    "\n",
    "        if cont>0:\n",
    "            format_candidates.append(\" \".join(sentence_ws[:cont]))\n",
    "        else:\n",
    "            format_candidates.append(\" \".join(sentence_ws))\n",
    "\n",
    "    \n",
    "    return format_candidates\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "source": [
    "filtered_e1 = filter_summaries(e1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "source": [
    "evaluation(e1, titles, patents, 'hts_e1')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('estudos': conda)"
  },
  "interpreter": {
   "hash": "8189520348208f2d7a55cd5e08e528a8ea0eb6334cdd1bc6eb49a516298cd84a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}